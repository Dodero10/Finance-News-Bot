#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script cháº¡y phÃ¢n tÃ­ch vÃ  lÆ°u káº¿t quáº£
"""

import sys
import os
from pathlib import Path
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend

# Import class tá»« file analysis
sys.path.append(str(Path(__file__).parent))
from compare_agents_visualization import AgentEvaluator

def save_results_to_file(results_df, evaluator, output_dir):
    """LÆ°u káº¿t quáº£ phÃ¢n tÃ­ch vÃ o file text"""
    
    results_file = output_dir / "analysis_results.txt"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        f.write("PHÃ‚N TÃCH SO SÃNH CÃC AGENT THEO Äá»˜ KHÃ“\n")
        f.write("="*80 + "\n\n")
        
        f.write("CÃC METRICS ÄÆ¯á»¢C ÄÃNH GIA:\n")
        f.write("- Accuracy: Tá»‰ lá»‡ agent gá»i tools hoÃ n toÃ n Ä‘Ãºng (failed_tools_count = 0)\n")
        f.write("- F1 Score: Äiá»ƒm F1 dá»±a trÃªn viá»‡c gá»i tool thÃ nh cÃ´ng\n")
        f.write("- Tool Fail Rate: Tá»‰ lá»‡ gá»i tool tháº¥t báº¡i\n\n")
        
        f.write("Báº¢NG Káº¾T QUáº¢ CHI TIáº¾T:\n")
        f.write("-" * 80 + "\n")
        f.write(results_df.to_string(index=False))
        f.write("\n\n")
        
        f.write("Tá»”NG Káº¾T THEO AGENT (Trung bÃ¬nh):\n")
        f.write("-" * 80 + "\n")
        summary = results_df.groupby('Agent').agg({
            'Accuracy': 'mean',
            'F1_Score': 'mean',
            'Precision': 'mean',
            'Recall': 'mean',
            'Tool_Precision': 'mean',
            'Tool_Recall': 'mean',
            'Tool_Fail_Rate': 'mean',
            'Sample_Count': 'sum'
        }).round(3)
        f.write(summary.to_string())
        f.write("\n\n")
        
        f.write("Xáº¾P Háº NG THEO METRICS:\n")
        f.write("-" * 80 + "\n")
        
        f.write("1. ACCURACY (cao nháº¥t -> tháº¥p nháº¥t):\n")
        accuracy_ranking = summary.sort_values('Accuracy', ascending=False)
        for i, (agent, row) in enumerate(accuracy_ranking.iterrows(), 1):
            f.write(f"{i}. {agent}: {row['Accuracy']:.3f}\n")
        
        f.write("\n2. F1 SCORE (cao nháº¥t -> tháº¥p nháº¥t):\n")
        f1_ranking = summary.sort_values('F1_Score', ascending=False)
        for i, (agent, row) in enumerate(f1_ranking.iterrows(), 1):
            f.write(f"{i}. {agent}: {row['F1_Score']:.3f}\n")
        
        f.write("\n3. TOOL SUCCESS RATE (tháº¥p nháº¥t fail rate -> cao nháº¥t):\n")
        tool_ranking = summary.sort_values('Tool_Fail_Rate', ascending=True)
        for i, (agent, row) in enumerate(tool_ranking.iterrows(), 1):
            success_rate = 1 - row['Tool_Fail_Rate']
            f.write(f"{i}. {agent}: {success_rate:.3f} (fail rate: {row['Tool_Fail_Rate']:.3f})\n")
        
        f.write("\n\nKáº¾T LUáº¬N:\n")
        f.write("-" * 80 + "\n")
        
        # TÃ¬m agent tá»‘t nháº¥t
        best_accuracy = accuracy_ranking.index[0]
        best_f1 = f1_ranking.index[0]
        best_tool = tool_ranking.index[0]
        
        f.write(f"- Agent tá»‘t nháº¥t vá» Accuracy: {best_accuracy} ({accuracy_ranking.loc[best_accuracy, 'Accuracy']:.3f})\n")
        f.write(f"- Agent tá»‘t nháº¥t vá» F1 Score: {best_f1} ({f1_ranking.loc[best_f1, 'F1_Score']:.3f})\n")
        f.write(f"- Agent Ã­t lá»—i tool nháº¥t: {best_tool} (success rate: {1-tool_ranking.loc[best_tool, 'Tool_Fail_Rate']:.3f})\n")
        
        # PhÃ¢n tÃ­ch theo Ä‘á»™ khÃ³
        f.write("\nPHÃ‚N TÃCH THEO Äá»˜ KHÃ“:\n")
        for difficulty in ['dá»…', 'khÃ³']:
            f.write(f"\nCÃ¢u há»i {difficulty}:\n")
            diff_data = results_df[results_df['Difficulty'] == difficulty]
            diff_summary = diff_data.groupby('Agent')[['Accuracy', 'F1_Score', 'Tool_Fail_Rate']].mean()
            
            f.write(f"- Accuracy cao nháº¥t: {diff_summary['Accuracy'].idxmax()} ({diff_summary['Accuracy'].max():.3f})\n")
            f.write(f"- F1 Score cao nháº¥t: {diff_summary['F1_Score'].idxmax()} ({diff_summary['F1_Score'].max():.3f})\n")
            f.write(f"- Tool fail rate tháº¥p nháº¥t: {diff_summary['Tool_Fail_Rate'].idxmin()} ({diff_summary['Tool_Fail_Rate'].min():.3f})\n")

def create_readme(output_dir):
    """Táº¡o file README Ä‘á»ƒ giáº£i thÃ­ch káº¿t quáº£"""
    readme_file = output_dir / "README.md"
    
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write("# Káº¿t quáº£ So sÃ¡nh cÃ¡c Agent\n\n")
        
        f.write("## Cáº¥u trÃºc thÆ° má»¥c\n\n")
        f.write("```\n")
        f.write("evaluation/results_visualization/figures/comprehensive/\n")
        f.write("â”œâ”€â”€ README.md                          # File nÃ y - hÆ°á»›ng dáº«n Ä‘á»c káº¿t quáº£\n")
        f.write("â”œâ”€â”€ analysis_results.txt               # Káº¿t quáº£ phÃ¢n tÃ­ch chi tiáº¿t dáº¡ng text\n")
        f.write("â”œâ”€â”€ detailed_results.csv               # Dá»¯ liá»‡u chi tiáº¿t dáº¡ng CSV\n")
        f.write("â”œâ”€â”€ agent_comparison_overview.png      # Biá»ƒu Ä‘á»“ tá»•ng quan so sÃ¡nh 4 metrics\n")
        f.write("â””â”€â”€ agent_comparison_detailed.png      # Biá»ƒu Ä‘á»“ chi tiáº¿t theo Ä‘á»™ khÃ³\n")
        f.write("```\n\n")
        
        f.write("## CÃ¡c Agent Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡\n\n")
        f.write("1. **React Agent**: Kiáº¿n trÃºc ReAct cÆ¡ báº£n\n")
        f.write("2. **ReWOO Agent**: Kiáº¿n trÃºc ReWOO (Reasoning WithOut Observation)\n")
        f.write("3. **Reflexion Agent**: Kiáº¿n trÃºc Reflexion vá»›i kháº£ nÄƒng self-reflection\n")
        f.write("4. **Multi-Agent**: Kiáº¿n trÃºc multi-agent do báº¡n Ä‘á» xuáº¥t\n\n")
        
        f.write("## Metrics Ä‘Ã¡nh giÃ¡\n\n")
        f.write("### 1. Accuracy\n")
        f.write("- **Äá»‹nh nghÄ©a**: Tá»‰ lá»‡ agent gá»i tools hoÃ n toÃ n Ä‘Ãºng\n")
        f.write("- **CÃ´ng thá»©c**: (Sá»‘ cÃ¢u cÃ³ failed_tools_count = 0) / Tá»•ng sá»‘ cÃ¢u\n")
        f.write("- **Giáº£i thÃ­ch**: Äo lÆ°á»ng kháº£ nÄƒng gá»i tool chÃ­nh xÃ¡c cá»§a agent\n\n")
        
        f.write("### 2. F1 Score\n")
        f.write("- **Äá»‹nh nghÄ©a**: Äiá»ƒm F1 dá»±a trÃªn viá»‡c gá»i tool thÃ nh cÃ´ng\n")
        f.write("- **CÃ´ng thá»©c**: 2 * (Precision * Recall) / (Precision + Recall)\n")
        f.write("- **Giáº£i thÃ­ch**: CÃ¢n báº±ng giá»¯a precision vÃ  recall trong viá»‡c sá»­ dá»¥ng tools\n\n")
        
        f.write("### 3. Tool Fail Rate\n")
        f.write("- **Äá»‹nh nghÄ©a**: Tá»‰ lá»‡ gá»i tool tháº¥t báº¡i\n")
        f.write("- **CÃ´ng thá»©c**: (Sá»‘ cÃ¢u cÃ³ failed_tools_count > 0) / Tá»•ng sá»‘ cÃ¢u cÃ³ gá»i tool\n")
        f.write("- **Giáº£i thÃ­ch**: Äo lÆ°á»ng Ä‘á»™ tin cáº­y khi sá»­ dá»¥ng tools (tháº¥p hÆ¡n = tá»‘t hÆ¡n)\n\n")
        
        f.write("## CÃ¡ch Ä‘á»c káº¿t quáº£\n\n")
        f.write("### Biá»ƒu Ä‘á»“ Overview (agent_comparison_overview.png)\n")
        f.write("- **GÃ³c trÃªn trÃ¡i**: Accuracy theo Ä‘á»™ khÃ³\n")
        f.write("- **GÃ³c trÃªn pháº£i**: F1 Score theo Ä‘á»™ khÃ³\n")
        f.write("- **GÃ³c dÆ°á»›i trÃ¡i**: Tool Fail Rate theo Ä‘á»™ khÃ³\n")
        f.write("- **GÃ³c dÆ°á»›i pháº£i**: Heatmap tá»•ng quan (mÃ u xanh = tá»‘t, mÃ u Ä‘á» = kÃ©m)\n\n")
        
        f.write("### Biá»ƒu Ä‘á»“ Detailed (agent_comparison_detailed.png)\n")
        f.write("- So sÃ¡nh trá»±c tiáº¿p giá»¯a cÃ¢u há»i dá»… vÃ  khÃ³ cho tá»«ng metric\n")
        f.write("- Cá»™t xanh: CÃ¢u há»i dá»…\n")
        f.write("- Cá»™t cam: CÃ¢u há»i khÃ³\n\n")
        
        f.write("## Files káº¿t quáº£\n\n")
        f.write("### analysis_results.txt\n")
        f.write("- Chá»©a toÃ n bá»™ káº¿t quáº£ phÃ¢n tÃ­ch dáº¡ng text\n")
        f.write("- Báº£ng xáº¿p háº¡ng theo tá»«ng metric\n")
        f.write("- Káº¿t luáº­n vÃ  nháº­n xÃ©t\n\n")
        
        f.write("### detailed_results.csv\n")
        f.write("- Dá»¯ liá»‡u chi tiáº¿t Ä‘á»ƒ phÃ¢n tÃ­ch thÃªm\n")
        f.write("- CÃ³ thá»ƒ import vÃ o Excel/Python Ä‘á»ƒ xá»­ lÃ½ thÃªm\n\n")
        
        f.write("## CÃ¡ch hiá»ƒu káº¿t quáº£\n\n")
        f.write("1. **Agent tá»‘t nháº¥t tá»•ng thá»ƒ**: Xem xáº¿p háº¡ng trung bÃ¬nh cÃ¡c metrics\n")
        f.write("2. **Agent á»•n Ä‘á»‹nh nháº¥t**: Agent cÃ³ hiá»‡u suáº¥t Ä‘á»u giá»¯a cÃ¢u dá»… vÃ  khÃ³\n")
        f.write("3. **Agent phÃ¹ há»£p cÃ¢u khÃ³**: Xem hiá»‡u suáº¥t riÃªng vá»›i difficulty = 'khÃ³'\n")
        f.write("4. **Agent Ä‘Ã¡ng tin cáº­y nháº¥t**: Agent cÃ³ Tool Fail Rate tháº¥p nháº¥t\n")

def main():
    print("Báº¯t Ä‘áº§u phÃ¢n tÃ­ch vÃ  táº¡o biá»ƒu Ä‘á»“...")
    
    # ÄÆ°á»ng dáº«n Ä‘áº¿n folder chá»©a file káº¿t quáº£
    data_path = Path("evaluation/data_eval/results")
    
    # Táº¡o evaluator
    evaluator = AgentEvaluator(data_path)
    
    # PhÃ¢n tÃ­ch theo Ä‘á»™ khÃ³
    print("Äang phÃ¢n tÃ­ch dá»¯ liá»‡u...")
    results_df = evaluator.analyze_by_difficulty()
    
    # Táº¡o thÆ° má»¥c output
    output_dir = Path("evaluation/results_visualization/figures/comprehensive")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("Äang táº¡o biá»ƒu Ä‘á»“...")
    # Táº¡o biá»ƒu Ä‘á»“ so sÃ¡nh
    fig1 = evaluator.create_comparison_plots(results_df)
    
    # Táº¡o biá»ƒu Ä‘á»“ chi tiáº¿t
    fig2 = evaluator.create_detailed_comparison(results_df)
    
    # LÆ°u biá»ƒu Ä‘á»“
    fig1.savefig(output_dir / "agent_comparison_overview.png", dpi=300, bbox_inches='tight')
    fig2.savefig(output_dir / "agent_comparison_detailed.png", dpi=300, bbox_inches='tight')
    
    print("Äang lÆ°u káº¿t quáº£...")
    # LÆ°u káº¿t quáº£ vÃ o file
    save_results_to_file(results_df, evaluator, output_dir)
    
    # LÆ°u CSV
    results_df.to_csv(output_dir / "detailed_results.csv", index=False, encoding='utf-8')
    
    # Táº¡o README
    create_readme(output_dir)
    
    print(f"\nâœ… HOÃ€N THÃ€NH! Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i:")
    print(f"ğŸ“ {output_dir}")
    print(f"\nğŸ“‹ CÃ¡c file Ä‘Ã£ táº¡o:")
    print(f"   ğŸ“„ README.md - HÆ°á»›ng dáº«n Ä‘á»c káº¿t quáº£")
    print(f"   ğŸ“„ analysis_results.txt - Káº¿t quáº£ phÃ¢n tÃ­ch chi tiáº¿t")
    print(f"   ğŸ“„ detailed_results.csv - Dá»¯ liá»‡u chi tiáº¿t")
    print(f"   ğŸ–¼ï¸ agent_comparison_overview.png - Biá»ƒu Ä‘á»“ tá»•ng quan")
    print(f"   ğŸ–¼ï¸ agent_comparison_detailed.png - Biá»ƒu Ä‘á»“ chi tiáº¿t")
    
    # In tÃ³m táº¯t nhanh
    print(f"\nğŸ“Š TÃ“M Táº®T NHANH:")
    summary = results_df.groupby('Agent').agg({
        'Accuracy': 'mean',
        'F1_Score': 'mean',
        'Precision': 'mean', 
        'Recall': 'mean',
        'Tool_Precision': 'mean',
        'Tool_Recall': 'mean',
        'Tool_Fail_Rate': 'mean'
    }).round(3)
    
    print("\nğŸ¯ Xáº¾P Háº NG ACCURACY:")
    for i, (agent, row) in enumerate(summary.sort_values('Accuracy', ascending=False).iterrows(), 1):
        print(f"   {i}. {agent}: {row['Accuracy']:.3f}")
    
    print("\nğŸ¯ Xáº¾P Háº NG F1 SCORE:")
    for i, (agent, row) in enumerate(summary.sort_values('F1_Score', ascending=False).iterrows(), 1):
        print(f"   {i}. {agent}: {row['F1_Score']:.3f} (P: {row['Precision']:.3f}, R: {row['Recall']:.3f})")
    
    print("\nğŸ¯ Xáº¾P Háº NG TOOL PRECISION:")
    for i, (agent, row) in enumerate(summary.sort_values('Tool_Precision', ascending=False).iterrows(), 1):
        print(f"   {i}. {agent}: {row['Tool_Precision']:.3f}")
    
    print("\nğŸ¯ Xáº¾P Háº NG TOOL RECALL:")
    for i, (agent, row) in enumerate(summary.sort_values('Tool_Recall', ascending=False).iterrows(), 1):
        print(f"   {i}. {agent}: {row['Tool_Recall']:.3f}")
    
    print("\nğŸ¯ Xáº¾P Háº NG TOOL SUCCESS (tháº¥p fail rate = tá»‘t):")
    for i, (agent, row) in enumerate(summary.sort_values('Tool_Fail_Rate', ascending=True).iterrows(), 1):
        success_rate = 1 - row['Tool_Fail_Rate']
        print(f"   {i}. {agent}: {success_rate:.3f}")
    
    return results_df

if __name__ == "__main__":
    results = main() 